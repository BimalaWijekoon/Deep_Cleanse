{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\nimport matplotlib\nmatplotlib.use('Agg')  # Set the backend to Agg to avoid display issues\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nimport urllib.request\nimport tarfile\nfrom pathlib import Path\nimport glob\nimport argparse\nimport re\nimport shutil\nimport sys\n\n# Handle Colab vs. Kaggle environment differences\nIN_COLAB = 'google.colab' in sys.modules\nIN_KAGGLE = 'kaggle_secrets' in sys.modules if not IN_COLAB else False\n\nif IN_COLAB:\n    # Colab directories\n    BASE_DIR = Path('/content')\n    MODEL_DIR = BASE_DIR / 'models'\n    LOG_DIR = BASE_DIR / 'logs'\n    WORKING_DIR = BASE_DIR / 'working'\nelse:\n    # Kaggle directories - updated to use /kaggle/working for all outputs\n    BASE_DIR = Path('/kaggle')\n    WORKING_DIR = BASE_DIR / 'working'\n    MODEL_DIR = WORKING_DIR / 'models'\n    LOG_DIR = WORKING_DIR / 'logs'\n\n# Create directories\nWORKING_DIR.mkdir(exist_ok=True, parents=True)\nMODEL_DIR.mkdir(exist_ok=True, parents=True)\nLOG_DIR.mkdir(exist_ok=True, parents=True)\n\n# Setup argument parser for checkpoint selection\ndef setup_arg_parser():\n    parser = argparse.ArgumentParser(description='Train a denoising autoencoder with checkpoint management')\n    parser.add_argument('--resume-from', type=str, default=None, \n                        help='Checkpoint file to resume training from')\n    parser.add_argument('--keep-checkpoints', type=int, default=3, \n                        help='Number of recent checkpoints to keep')\n    parser.add_argument('--epochs', type=int, default=100, \n                        help='Number of epochs to train')\n    parser.add_argument('--batch-size', type=int, default=32, \n                        help='Batch size for training')\n    \n    # Parse only known arguments (ignores additional args passed in by Colab/Jupyter)\n    return parser.parse_known_args()[0]\n\n# Check for GPU availability and configure\ndef setup_gpus():\n    \"\"\"Configure TensorFlow to use multiple GPUs if available\"\"\"\n    gpus = tf.config.list_physical_devices('GPU')\n    \n    if not gpus:\n        print(\"No GPUs found. Running on CPU.\")\n        return False\n    \n    print(f\"Found {len(gpus)} GPU(s):\")\n    for gpu in gpus:\n        print(f\"  - {gpu.name}\")\n    \n    # REMOVED mixed precision policy to avoid 'Cast' layer issues\n    # This is the key change to make the model more portable\n    \n    # Multi-GPU strategy\n    if len(gpus) > 1:\n        strategy = tf.distribute.MirroredStrategy()\n        print(f\"Using MirroredStrategy with {strategy.num_replicas_in_sync} devices\")\n        return strategy\n    else:\n        print(\"Using default strategy (single GPU)\")\n        return tf.distribute.get_strategy()\n\ndef build_denoising_autoencoder(strategy=None, input_shape=(256, 256, 3)):\n    \"\"\"\n    Build a professional-level U-Net style denoising autoencoder for images\n    with multi-GPU support if available\n    \"\"\"\n    if strategy:\n        with strategy.scope():\n            # Input layer\n            inputs = layers.Input(shape=input_shape)\n            \n            # Encoder\n            # Block 1\n            x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n            x = layers.BatchNormalization()(x)\n            x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n            x = layers.BatchNormalization()(x)\n            x1 = x  # Skip connection 1\n            x = layers.MaxPooling2D((2, 2))(x)\n            \n            # Block 2\n            x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n            x = layers.BatchNormalization()(x)\n            x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n            x = layers.BatchNormalization()(x)\n            x2 = x  # Skip connection 2\n            x = layers.MaxPooling2D((2, 2))(x)\n            \n            # Block 3\n            x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n            x = layers.BatchNormalization()(x)\n            x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n            x = layers.BatchNormalization()(x)\n            x3 = x  # Skip connection 3\n            x = layers.MaxPooling2D((2, 2))(x)\n            \n            # Block 4 (Bottleneck)\n            x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n            x = layers.BatchNormalization()(x)\n            x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n            x = layers.BatchNormalization()(x)\n            \n            # Decoder\n            # Block 5\n            x = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)\n            x = layers.Concatenate()([x, x3])  # Skip connection from Block 3\n            x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n            x = layers.BatchNormalization()(x)\n            x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n            x = layers.BatchNormalization()(x)\n            \n            # Block 6\n            x = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)\n            x = layers.Concatenate()([x, x2])  # Skip connection from Block 2\n            x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n            x = layers.BatchNormalization()(x)\n            x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n            x = layers.BatchNormalization()(x)\n            \n            # Block 7\n            x = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(x)\n            x = layers.Concatenate()([x, x1])  # Skip connection from Block 1\n            x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n            x = layers.BatchNormalization()(x)\n            x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n            x = layers.BatchNormalization()(x)\n            \n            # Output layer\n            outputs = layers.Conv2D(input_shape[2], (1, 1), activation='sigmoid')(x)\n            \n            # Create and compile model with Adam optimizer\n            # Using standard optimizer settings without mixed precision\n            optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n            \n            # Create model\n            model = models.Model(inputs, outputs)\n            model.compile(\n                optimizer=optimizer, \n                loss='mse', \n                metrics=['mae']\n            )\n    else:\n        # If no strategy provided, build with default scope\n        inputs = layers.Input(shape=input_shape)\n        \n        # Encoder\n        # Block 1\n        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n        x = layers.BatchNormalization()(x)\n        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        x1 = x  # Skip connection 1\n        x = layers.MaxPooling2D((2, 2))(x)\n        \n        # Block 2\n        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        x2 = x  # Skip connection 2\n        x = layers.MaxPooling2D((2, 2))(x)\n        \n        # Block 3\n        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        x3 = x  # Skip connection 3\n        x = layers.MaxPooling2D((2, 2))(x)\n        \n        # Block 4 (Bottleneck)\n        x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        \n        # Decoder\n        # Block 5\n        x = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)\n        x = layers.Concatenate()([x, x3])  # Skip connection from Block 3\n        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        \n        # Block 6\n        x = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)\n        x = layers.Concatenate()([x, x2])  # Skip connection from Block 2\n        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        \n        # Block 7\n        x = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(x)\n        x = layers.Concatenate()([x, x1])  # Skip connection from Block 1\n        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        \n        # Output layer\n        outputs = layers.Conv2D(input_shape[2], (1, 1), activation='sigmoid')(x)\n        \n        # Create model\n        model = models.Model(inputs, outputs)\n        model.compile(\n            optimizer='adam', \n            loss='mse', \n            metrics=['mae']\n        )\n    \n    return model\n\ndef download_BSD300_dataset():\n    \"\"\"\n    Download BSD300 dataset for training/testing the model\n    \"\"\"\n    data_dir = BASE_DIR / 'data'\n    data_dir.mkdir(exist_ok=True, parents=True)\n    \n    # Define BSD300 dataset URL\n    bsd_url = \"https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/BSDS300-images.tgz\"\n    bsd_file = data_dir / \"BSDS300-images.tgz\"\n    \n    # Check if we're in Kaggle and dataset already exists in Kaggle input\n    if IN_KAGGLE:\n        input_path = Path('/kaggle/input/bsd300')\n        if input_path.exists():\n            print(f\"Found BSD300 dataset in Kaggle input directory: {input_path}\")\n            return input_path\n    \n    # Download the dataset if it doesn't exist\n    if not bsd_file.exists():\n        print(f\"Downloading BSD300 dataset from {bsd_url}...\")\n        urllib.request.urlretrieve(bsd_url, bsd_file)\n        \n        # Extract the archive\n        with tarfile.open(bsd_file, 'r:gz') as tar:\n            tar.extractall(path=data_dir)\n        print(\"Dataset downloaded and extracted successfully!\")\n    else:\n        print(\"BSD300 dataset already exists in working directory.\")\n    \n    return data_dir / \"BSDS300\" / \"images\"\n\ndef create_and_save_model(strategy=None):\n    \"\"\"\n    Create the model with multi-GPU support and save it\n    \"\"\"\n    print(\"Building denoising autoencoder model...\")\n    model = build_denoising_autoencoder(strategy)\n    \n    # Show model architecture summary\n    model.summary()\n    \n    # Save the model architecture - using JSON for better portability\n    model_json = model.to_json()\n    with open(MODEL_DIR / \"denoising_autoencoder_architecture.json\", \"w\") as json_file:\n        json_file.write(model_json)\n    print(\"Model architecture saved to denoising_autoencoder_architecture.json\")\n    \n    # Save the initial model weights\n    model.save_weights(MODEL_DIR / \"denoising_autoencoder.00-0.0000.weights.h5\")\n    print(\"Initial model weights saved to denoising_autoencoder_weights.h5\")\n    \n    # Save the complete model - using SavedModel format for better portability\n    model.save(MODEL_DIR / \"denoising_autoencoder_model.keras\")  # SavedModel format by default with directory path\n\n    print(\"Complete model saved to denoising_autoencoder_model in TF SavedModel format\")\n    \n    # Also save in H5 format for backwards compatibility\n    model.save(MODEL_DIR / \"denoising_autoencoder_model.h5\")  # H5 format based on .h5 extension\n    print(\"Complete model also saved to denoising_autoencoder_model.h5\")\n    \n    return model\n\ndef load_model_from_checkpoint(checkpoint_path, strategy=None):\n    \"\"\"\n    Load model from a specific checkpoint\n    \n    Args:\n        checkpoint_path: Path to the checkpoint file\n        strategy: TensorFlow distribution strategy\n    \n    Returns:\n        Loaded model with weights from checkpoint\n    \"\"\"\n    print(f\"Loading model from checkpoint: {checkpoint_path}\")\n    \n    # First, create the model with the right architecture\n    if strategy:\n        with strategy.scope():\n            model = build_denoising_autoencoder(None)  # Strategy is already handled in the scope\n    else:\n        model = build_denoising_autoencoder()\n    \n    # Load weights from checkpoint\n    model.load_weights(checkpoint_path)\n    print(\"Model weights loaded successfully\")\n    \n    # Extract epoch number from checkpoint filename for resuming training\n    epoch_match = re.search(r'\\.(\\d+)-', os.path.basename(checkpoint_path))\n    initial_epoch = 0\n    if epoch_match:\n        initial_epoch = int(epoch_match.group(1))\n        print(f\"Will resume training from epoch {initial_epoch}\")\n    \n    return model, initial_epoch\n\ndef manage_checkpoints(keep_count=3, started_checkpoint=None):\n    \"\"\"\n    Manage checkpoints to save disk space\n    \n    Args:\n        keep_count: Number of recent checkpoints to keep\n        started_checkpoint: Path to the checkpoint we started with (always keep this one)\n    \"\"\"\n    # Get all checkpoint files in the model directory\n    checkpoint_pattern = str(MODEL_DIR / \"denoising_autoencoder.*.weights.h5\")\n    checkpoints = glob.glob(checkpoint_pattern)\n    \n    # If no checkpoints or too few to manage, just return\n    if len(checkpoints) <= keep_count:\n        return\n    \n    print(f\"Managing checkpoints. Keeping {keep_count} most recent checkpoints...\")\n    \n    # Extract epoch and loss info from filenames to sort\n    checkpoint_info = []\n    for cp in checkpoints:\n        # Skip the checkpoint we started from\n        if started_checkpoint and os.path.basename(cp) == os.path.basename(started_checkpoint):\n            continue\n            \n        # Extract epoch number for sorting\n        epoch_match = re.search(r'\\.(\\d+)-', os.path.basename(cp))\n        if epoch_match:\n            epoch = int(epoch_match.group(1))\n            checkpoint_info.append((cp, epoch))\n    \n    # Sort by epoch (descending)\n    checkpoint_info.sort(key=lambda x: x[1], reverse=True)\n    \n    # Keep the top 'keep_count' checkpoints, delete the rest\n    checkpoints_to_delete = checkpoint_info[keep_count:]\n    for cp, _ in checkpoints_to_delete:\n        print(f\"Removing old checkpoint: {os.path.basename(cp)}\")\n        os.remove(cp)\n\ndef train_model(model, train_images, val_images, args, initial_epoch=0):\n    \"\"\"\n    Train the denoising autoencoder model with optimized settings\n    and checkpoint management\n    \n    Args:\n        model: The model to train\n        train_images: Training images\n        val_images: Validation images\n        args: Command line arguments\n        initial_epoch: Epoch to resume training from\n    \n    Returns:\n        Trained model and training history\n    \"\"\"\n    # Set epochs and batch size\n    epochs = args.epochs\n    batch_size = args.batch_size\n    \n    # Calculate appropriate batch size based on GPU RAM\n    # For multi-GPU setup, we can increase batch size\n    # but we need to make it divisible by number of GPUs\n    gpus = len(tf.config.list_physical_devices('GPU'))\n    if gpus > 1:\n        # Make batch size divisible by number of GPUs\n        # and scale it up for multiple GPUs\n        batch_size = max(batch_size, 32 * gpus)\n        # Ensure divisibility\n        batch_size = batch_size - (batch_size % gpus) if batch_size % gpus != 0 else batch_size\n        print(f\"Using batch size of {batch_size} for {gpus} GPUs\")\n    \n    # Create checkpoint callback\n    checkpoint_callback = ModelCheckpoint(\n        filepath=MODEL_DIR / \"denoising_autoencoder.{epoch:02d}-{val_loss:.4f}.weights.h5\",\n        save_weights_only=True,\n        save_best_only=True,\n        monitor='val_loss'\n    )\n    \n    # TensorBoard callback for visualizing training\n    tensorboard_callback = TensorBoard(\n        log_dir=LOG_DIR,\n        histogram_freq=1,\n        write_graph=True,\n        update_freq='epoch'\n    )\n    \n    # Early stopping to prevent overfitting\n    early_stopping = EarlyStopping(\n        monitor='val_loss',\n        patience=20,\n        restore_best_weights=True\n    )\n    \n    # Custom callback for checkpoint management\n    class CheckpointManagerCallback(tf.keras.callbacks.Callback):\n        def __init__(self, keep_count, started_checkpoint):\n            super().__init__()\n            self.keep_count = keep_count\n            self.started_checkpoint = started_checkpoint\n            \n        def on_epoch_end(self, epoch, logs=None):\n            # Manage checkpoints every 5 epochs to avoid too frequent disk operations\n            if epoch % 5 == 0:\n                manage_checkpoints(self.keep_count, self.started_checkpoint)\n    \n    # Create the checkpoint manager callback\n    checkpoint_manager = CheckpointManagerCallback(\n        args.keep_checkpoints,\n        args.resume_from\n    )\n    \n    # Create noisy versions of the training and validation images\n    def add_noise(images, noise_factor=0.3):\n        noisy_images = images + noise_factor * np.random.normal(\n            loc=0.0, scale=1.0, size=images.shape\n        )\n        return np.clip(noisy_images, 0., 1.)\n    \n    train_noisy = add_noise(train_images)\n    val_noisy = add_noise(val_images)\n    \n    # Train the model\n    history = model.fit(\n        train_noisy, train_images,\n        epochs=epochs,\n        batch_size=batch_size,\n        validation_data=(val_noisy, val_images),\n        callbacks=[checkpoint_callback, early_stopping, tensorboard_callback, checkpoint_manager],\n        initial_epoch=initial_epoch\n    )\n    \n    # Save the final trained model in both SavedModel and H5 formats for maximum compatibility\n    # SavedModel format (recommended for TensorFlow 2.x)\n    model.save(MODEL_DIR / \"denoising_autoencoder_final.keras\")  # SavedModel format\n\n    print(\"Final model saved to denoising_autoencoder_final in TF SavedModel format\")\n    \n    # Also save in H5 format for backward compatibility\n    # Use 'tf' backend for saving to avoid mixed precision issues\n    model.save(MODEL_DIR / \"denoising_autoencoder_final.h5\")  # H5 format\n    print(\"Final model also saved to denoising_autoencoder_final.h5\")\n    \n    # Save the training history for later analysis\n    np.save(MODEL_DIR / 'training_history.npy', history.history)\n    \n    # Plot and save training curves\n    plt.figure(figsize=(12, 4))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper right')\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['mae'])\n    plt.plot(history.history['val_mae'])\n    plt.title('Model MAE')\n    plt.ylabel('MAE')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper right')\n    \n    plt.tight_layout()\n    plt.savefig(MODEL_DIR / 'training_curves.png', format='png')\n    \n    return model, history\n\ndef test_model(model):\n    \"\"\"\n    Create a simple test to verify the model works\n    \"\"\"\n    print(\"\\nTesting model with a simple example...\")\n    # Create a sample clean image (all ones for simplicity)\n    clean_img = np.ones((1, 256, 256, 3), dtype=np.float32) * 0.5\n    \n    # Add some noise\n    noise_factor = 0.3\n    noisy_img = clean_img + noise_factor * np.random.normal(\n        loc=0.0, scale=1.0, size=clean_img.shape).astype(np.float32)\n    noisy_img = np.clip(noisy_img, 0., 1.)\n    \n    # Use the model to denoise\n    denoised_img = model.predict(noisy_img)\n    \n    # Save the test images - ensure all arrays are float32 compatible with matplotlib\n    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n    \n    # Convert arrays to float32 and clip to [0,1] range\n    clean_display = np.clip(clean_img[0].astype(np.float32), 0, 1)\n    noisy_display = np.clip(noisy_img[0].astype(np.float32), 0, 1) \n    denoised_display = np.clip(denoised_img[0].astype(np.float32), 0, 1)\n    \n    axes[0].imshow(clean_display)\n    axes[0].set_title('Original')\n    axes[0].axis('off')\n    \n    axes[1].imshow(noisy_display)\n    axes[1].set_title('Noisy')\n    axes[1].axis('off')\n    \n    axes[2].imshow(denoised_display)\n    axes[2].set_title('Denoised')\n    axes[2].axis('off')\n    \n    plt.tight_layout()\n    \n    # Try alternative method to save figure that's more reliable with float arrays\n    plt.savefig(str(MODEL_DIR / 'test_results.png'), format='png', dpi=100)\n    print(\"Test results saved to test_results.png\")\n\ndef prepare_data_from_bsd300(data_path, image_size=(256, 256), split_ratio=0.8):\n    \"\"\"\n    Prepare training and validation data from BSD300 dataset\n    \n    Args:\n        data_path: Path to the BSD300 images directory\n        image_size: Size to which images will be resized\n        split_ratio: Ratio for train/validation split\n    \n    Returns:\n        train_images, val_images as numpy arrays\n    \"\"\"\n    # Find all images in the train folder\n    train_path = data_path / \"train\"\n    image_files = glob.glob(str(train_path / \"*.jpg\"))\n    \n    if not image_files:\n        print(f\"No images found in {train_path}. Using 'test' folder instead.\")\n        train_path = data_path / \"test\"\n        image_files = glob.glob(str(train_path / \"*.jpg\"))\n    \n    if not image_files:\n        raise ValueError(f\"No images found in {data_path}\")\n    \n    print(f\"Found {len(image_files)} images for training/validation\")\n    \n    # Load and preprocess images - optimize for memory\n    # Process in batches to avoid memory issues\n    batch_size = 32\n    images = []\n    \n    for i in range(0, len(image_files), batch_size):\n        batch_files = image_files[i:i+batch_size]\n        batch_images = []\n        \n        for img_path in batch_files:\n            img = load_img(img_path, target_size=image_size)\n            img_array = img_to_array(img) / 255.0  # Normalize to [0,1]\n            batch_images.append(img_array)\n        \n        images.extend(batch_images)\n        print(f\"Processed {min(i+batch_size, len(image_files))}/{len(image_files)} images\")\n    \n    # Convert to numpy array\n    images = np.array(images, dtype=np.float32)  # Explicitly use float32\n    \n    # Split into training and validation sets\n    split_idx = int(len(images) * split_ratio)\n    train_images = images[:split_idx]\n    val_images = images[split_idx:]\n    \n    print(f\"Training images: {train_images.shape}\")\n    print(f\"Validation images: {val_images.shape}\")\n    \n    # Save preprocessed data to avoid reprocessing\n    np.save(BASE_DIR / 'working/train_images.npy', train_images)\n    np.save(BASE_DIR / 'working/val_images.npy', val_images)\n    print(\"Preprocessed data saved to working directory\")\n    \n    return train_images, val_images\n\ndef check_for_existing_data():\n    \"\"\"Check if preprocessed data already exists in input folder\"\"\"\n    # Make paths based on environment\n    if IN_KAGGLE:\n        train_path = Path('/kaggle/input/preprocessed-bsd300/train_images.npy')\n        val_path = Path('/kaggle/input/preprocessed-bsd300/val_images.npy')\n    else:\n        # For Colab, look in working directory\n        train_path = BASE_DIR / 'working/train_images.npy'\n        val_path = BASE_DIR / 'working/val_images.npy'\n    \n    if train_path.exists() and val_path.exists():\n        print(\"Found preprocessed data in input folder\")\n        train_images = np.load(train_path)\n        val_images = np.load(val_path)\n        print(f\"Loaded training images: {train_images.shape}\")\n        print(f\"Loaded validation images: {val_images.shape}\")\n        return train_images, val_images\n    \n    return None, None\n\ndef main():\n    print(\"Starting Image Denoising Autoencoder setup...\")\n    print(f\"Running in {'Colab' if IN_COLAB else 'Kaggle' if IN_KAGGLE else 'other'} environment\")\n    \n    # Parse command line arguments\n    args = setup_arg_parser()\n    \n    # Setup GPUs and get strategy for multi-GPU training\n    strategy = setup_gpus()\n    \n    # Check if preprocessed data already exists (useful for continuing work)\n    train_images, val_images = check_for_existing_data()\n    \n    if train_images is None:\n        # Download dataset if needed\n        data_path = download_BSD300_dataset()\n        print(f\"Dataset available at: {data_path}\")\n        \n        # Prepare data\n        train_images, val_images = prepare_data_from_bsd300(data_path)\n    \n    # Initial epoch to start from\n    initial_epoch = 0\n    \n    # Check if we're resuming from a checkpoint\n    if args.resume_from:\n        checkpoint_path = args.resume_from\n        if not os.path.isabs(checkpoint_path):\n            # If relative path, assume it's relative to MODEL_DIR\n            checkpoint_path = str(MODEL_DIR / checkpoint_path)\n        \n        if os.path.exists(checkpoint_path):\n            model, initial_epoch = load_model_from_checkpoint(checkpoint_path, strategy)\n        else:\n            print(f\"Warning: Checkpoint {checkpoint_path} not found. Starting from scratch.\")\n            model = create_and_save_model(strategy)\n    else:\n        # Create and save model (with multi-GPU support)\n        model = create_and_save_model(strategy)\n    \n    # Train model with checkpoint management\n    model, history = train_model(model, train_images, val_images, args, initial_epoch)\n    \n    # Run a simple test and save results\n    test_model(model)\n    \n    # Final checkpoint management\n    manage_checkpoints(args.keep_checkpoints, args.resume_from)\n    \n    print(\"\\nSetup complete!\")\n    print(f\"Model and related files saved to: {MODEL_DIR}\")\n    print(f\"Logs saved to: {LOG_DIR}\")\n    print(\"\\nNext steps:\")\n    print(\"1. Download the model files\")\n    print(\"2. Use the SavedModel format at 'denoising_autoencoder_final' for best compatibility\")\n    print(\"3. Alternatively, use the H5 model at 'denoising_autoencoder_final.h5'\")\n    print(\"4. When loading the model, use tf.keras.models.load_model('/path/to/denoising_autoencoder_final')\")\n    print(\"   or model = tf.keras.models.load_model('/path/to/denoising_autoencoder_final.h5')\")\n    print(\"5. For best portability, avoid using mixed precision when loading and using the model\")\n    print(\"6. View training results in TensorBoard with: tensorboard --logdir={}\".format(LOG_DIR))\n\nif __name__ == \"__main__\":\n    # Set the TF_FORCE_GPU_ALLOW_GROWTH environment variable to avoid memory issues\n    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n    \n    # Set memory growth for GPUs to avoid memory allocation errors\n    physical_devices = tf.config.list_physical_devices('GPU')\n    for device in physical_devices:\n        try:\n            tf.config.experimental.set_memory_growth(device, True)\n            print(f\"Memory growth enabled for {device}\")\n        except:\n            print(f\"Could not set memory growth for {device}\")\n    \n    # Run the main function\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-24T08:45:08.165939Z","iopub.execute_input":"2025-03-24T08:45:08.166249Z","iopub.status.idle":"2025-03-24T08:52:54.386816Z","shell.execute_reply.started":"2025-03-24T08:45:08.166227Z","shell.execute_reply":"2025-03-24T08:52:54.386086Z"}},"outputs":[{"name":"stdout","text":"Memory growth enabled for PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\nMemory growth enabled for PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\nStarting Image Denoising Autoencoder setup...\nRunning in other environment\nFound 2 GPU(s):\n  - /physical_device:GPU:0\n  - /physical_device:GPU:1\nUsing MirroredStrategy with 2 devices\nFound preprocessed data in input folder\nLoaded training images: (160, 256, 256, 3)\nLoaded validation images: (40, 256, 256, 3)\nBuilding denoising autoencoder model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m896\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m128\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m9,248\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m128\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,584\u001b[0m │ batch_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m131,200\u001b[0m │ batch_normalization_7… │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                           │                        │                │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m295,040\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,584\u001b[0m │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m32,832\u001b[0m │ batch_normalization_9… │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m73,792\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m8,224\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_2[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m18,464\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m128\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m9,248\u001b[0m │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m128\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m99\u001b[0m │ batch_normalization_1… │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalization_4… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ batch_normalization_7… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                           │                        │                │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ batch_normalization_9… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │ batch_normalization_1… │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,931,299\u001b[0m (7.37 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,931,299</span> (7.37 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,928,483\u001b[0m (7.36 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,928,483</span> (7.36 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,816\u001b[0m (11.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,816</span> (11.00 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Model architecture saved to denoising_autoencoder_architecture.json\nInitial model weights saved to denoising_autoencoder_weights.h5\nComplete model saved to denoising_autoencoder_model in TF SavedModel format\nComplete model also saved to denoising_autoencoder_model.h5\nUsing batch size of 64 for 2 GPUs\nEpoch 1/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7s/step - loss: 0.1184 - mae: 0.2762 - val_loss: 0.0614 - val_mae: 0.2055\nEpoch 2/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0694 - mae: 0.2071 - val_loss: 0.0614 - val_mae: 0.2063\nEpoch 3/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0487 - mae: 0.1731 - val_loss: 0.0616 - val_mae: 0.2080\nEpoch 4/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0391 - mae: 0.1551 - val_loss: 0.0592 - val_mae: 0.2053\nEpoch 5/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0322 - mae: 0.1402 - val_loss: 0.0528 - val_mae: 0.1920\nEpoch 6/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771ms/step - loss: 0.0264 - mae: 0.1276Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.01-0.0614.weights.h5\nRemoving old checkpoint: denoising_autoencoder.00-0.0000.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0263 - mae: 0.1271 - val_loss: 0.0484 - val_mae: 0.1822\nEpoch 7/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - loss: 0.0224 - mae: 0.1164 - val_loss: 0.0453 - val_mae: 0.1742\nEpoch 8/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0207 - mae: 0.1114 - val_loss: 0.0473 - val_mae: 0.1797\nEpoch 9/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0182 - mae: 0.1039 - val_loss: 0.0495 - val_mae: 0.1849\nEpoch 10/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0168 - mae: 0.0994 - val_loss: 0.0498 - val_mae: 0.1851\nEpoch 11/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - loss: 0.0153 - mae: 0.0952Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.04-0.0592.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0153 - mae: 0.0954 - val_loss: 0.0498 - val_mae: 0.1848\nEpoch 12/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0139 - mae: 0.0900 - val_loss: 0.0501 - val_mae: 0.1847\nEpoch 13/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0134 - mae: 0.0882 - val_loss: 0.0497 - val_mae: 0.1836\nEpoch 14/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0121 - mae: 0.0836 - val_loss: 0.0489 - val_mae: 0.1819\nEpoch 15/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0119 - mae: 0.0827 - val_loss: 0.0483 - val_mae: 0.1807\nEpoch 16/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0119 - mae: 0.0825 - val_loss: 0.0478 - val_mae: 0.1795\nEpoch 17/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0113 - mae: 0.0806 - val_loss: 0.0474 - val_mae: 0.1785\nEpoch 18/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0106 - mae: 0.0775 - val_loss: 0.0462 - val_mae: 0.1763\nEpoch 19/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0104 - mae: 0.0772 - val_loss: 0.0454 - val_mae: 0.1747\nEpoch 20/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - loss: 0.0101 - mae: 0.0750 - val_loss: 0.0445 - val_mae: 0.1728\nEpoch 21/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676ms/step - loss: 0.0101 - mae: 0.0757Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.06-0.0484.weights.h5\nRemoving old checkpoint: denoising_autoencoder.05-0.0528.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0101 - mae: 0.0757 - val_loss: 0.0442 - val_mae: 0.1720\nEpoch 22/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0107 - mae: 0.0774 - val_loss: 0.0444 - val_mae: 0.1720\nEpoch 23/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - loss: 0.0095 - mae: 0.0723 - val_loss: 0.0436 - val_mae: 0.1705\nEpoch 24/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0092 - mae: 0.0714 - val_loss: 0.0434 - val_mae: 0.1701\nEpoch 25/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0092 - mae: 0.0714 - val_loss: 0.0430 - val_mae: 0.1693\nEpoch 26/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778ms/step - loss: 0.0086 - mae: 0.0687Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.23-0.0436.weights.h5\nRemoving old checkpoint: denoising_autoencoder.21-0.0442.weights.h5\nRemoving old checkpoint: denoising_autoencoder.20-0.0445.weights.h5\nRemoving old checkpoint: denoising_autoencoder.07-0.0453.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0088 - mae: 0.0693 - val_loss: 0.0426 - val_mae: 0.1682\nEpoch 27/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0091 - mae: 0.0706 - val_loss: 0.0421 - val_mae: 0.1672\nEpoch 28/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0089 - mae: 0.0704 - val_loss: 0.0417 - val_mae: 0.1666\nEpoch 29/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0091 - mae: 0.0708 - val_loss: 0.0413 - val_mae: 0.1657\nEpoch 30/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0084 - mae: 0.0681 - val_loss: 0.0415 - val_mae: 0.1660\nEpoch 31/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694ms/step - loss: 0.0089 - mae: 0.0706Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.27-0.0421.weights.h5\nRemoving old checkpoint: denoising_autoencoder.26-0.0426.weights.h5\nRemoving old checkpoint: denoising_autoencoder.25-0.0430.weights.h5\nRemoving old checkpoint: denoising_autoencoder.24-0.0434.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0088 - mae: 0.0704 - val_loss: 0.0412 - val_mae: 0.1655\nEpoch 32/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0090 - mae: 0.0712 - val_loss: 0.0404 - val_mae: 0.1638\nEpoch 33/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0085 - mae: 0.0680 - val_loss: 0.0400 - val_mae: 0.1630\nEpoch 34/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0087 - mae: 0.0694 - val_loss: 0.0400 - val_mae: 0.1632\nEpoch 35/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0083 - mae: 0.0678 - val_loss: 0.0397 - val_mae: 0.1624\nEpoch 36/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669ms/step - loss: 0.0081 - mae: 0.0664Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.32-0.0404.weights.h5\nRemoving old checkpoint: denoising_autoencoder.31-0.0412.weights.h5\nRemoving old checkpoint: denoising_autoencoder.29-0.0413.weights.h5\nRemoving old checkpoint: denoising_autoencoder.28-0.0417.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0081 - mae: 0.0667 - val_loss: 0.0393 - val_mae: 0.1616\nEpoch 37/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0085 - mae: 0.0687 - val_loss: 0.0390 - val_mae: 0.1611\nEpoch 38/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0077 - mae: 0.0647 - val_loss: 0.0389 - val_mae: 0.1607\nEpoch 39/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0078 - mae: 0.0652 - val_loss: 0.0381 - val_mae: 0.1590\nEpoch 40/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0084 - mae: 0.0680 - val_loss: 0.0376 - val_mae: 0.1583\nEpoch 41/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791ms/step - loss: 0.0081 - mae: 0.0668Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.37-0.0390.weights.h5\nRemoving old checkpoint: denoising_autoencoder.36-0.0393.weights.h5\nRemoving old checkpoint: denoising_autoencoder.35-0.0397.weights.h5\nRemoving old checkpoint: denoising_autoencoder.33-0.0400.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0083 - mae: 0.0676 - val_loss: 0.0383 - val_mae: 0.1599\nEpoch 42/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0079 - mae: 0.0655 - val_loss: 0.0370 - val_mae: 0.1574\nEpoch 43/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0076 - mae: 0.0645 - val_loss: 0.0368 - val_mae: 0.1567\nEpoch 44/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0076 - mae: 0.0641 - val_loss: 0.0364 - val_mae: 0.1555\nEpoch 45/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0078 - mae: 0.0654 - val_loss: 0.0355 - val_mae: 0.1537\nEpoch 46/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787ms/step - loss: 0.0074 - mae: 0.0632Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.43-0.0368.weights.h5\nRemoving old checkpoint: denoising_autoencoder.42-0.0370.weights.h5\nRemoving old checkpoint: denoising_autoencoder.40-0.0376.weights.h5\nRemoving old checkpoint: denoising_autoencoder.39-0.0381.weights.h5\nRemoving old checkpoint: denoising_autoencoder.38-0.0389.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0074 - mae: 0.0632 - val_loss: 0.0353 - val_mae: 0.1537\nEpoch 47/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0074 - mae: 0.0639 - val_loss: 0.0357 - val_mae: 0.1546\nEpoch 48/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0073 - mae: 0.0632 - val_loss: 0.0355 - val_mae: 0.1547\nEpoch 49/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0084 - mae: 0.0688 - val_loss: 0.0349 - val_mae: 0.1535\nEpoch 50/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0071 - mae: 0.0618 - val_loss: 0.0333 - val_mae: 0.1499\nEpoch 51/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690ms/step - loss: 0.0070 - mae: 0.0615Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.46-0.0353.weights.h5\nRemoving old checkpoint: denoising_autoencoder.45-0.0355.weights.h5\nRemoving old checkpoint: denoising_autoencoder.44-0.0364.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0071 - mae: 0.0620 - val_loss: 0.0322 - val_mae: 0.1469\nEpoch 52/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0072 - mae: 0.0624 - val_loss: 0.0329 - val_mae: 0.1486\nEpoch 53/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0070 - mae: 0.0613 - val_loss: 0.0336 - val_mae: 0.1507\nEpoch 54/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0074 - mae: 0.0635 - val_loss: 0.0327 - val_mae: 0.1487\nEpoch 55/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0072 - mae: 0.0624 - val_loss: 0.0325 - val_mae: 0.1476\nEpoch 56/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806ms/step - loss: 0.0080 - mae: 0.0668Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.49-0.0349.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0080 - mae: 0.0669 - val_loss: 0.0312 - val_mae: 0.1447\nEpoch 57/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0071 - mae: 0.0622 - val_loss: 0.0314 - val_mae: 0.1454\nEpoch 58/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0070 - mae: 0.0615 - val_loss: 0.0315 - val_mae: 0.1459\nEpoch 59/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - loss: 0.0081 - mae: 0.0670 - val_loss: 0.0301 - val_mae: 0.1429\nEpoch 60/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0083 - mae: 0.0683 - val_loss: 0.0301 - val_mae: 0.1424\nEpoch 61/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665ms/step - loss: 0.0070 - mae: 0.0611Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.50-0.0333.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0071 - mae: 0.0617 - val_loss: 0.0305 - val_mae: 0.1426\nEpoch 62/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0069 - mae: 0.0610 - val_loss: 0.0299 - val_mae: 0.1416\nEpoch 63/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0073 - mae: 0.0633 - val_loss: 0.0302 - val_mae: 0.1431\nEpoch 64/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0071 - mae: 0.0623 - val_loss: 0.0299 - val_mae: 0.1426\nEpoch 65/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0072 - mae: 0.0629 - val_loss: 0.0291 - val_mae: 0.1401\nEpoch 66/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688ms/step - loss: 0.0071 - mae: 0.0627Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.62-0.0299.weights.h5\nRemoving old checkpoint: denoising_autoencoder.59-0.0301.weights.h5\nRemoving old checkpoint: denoising_autoencoder.56-0.0312.weights.h5\nRemoving old checkpoint: denoising_autoencoder.51-0.0322.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0071 - mae: 0.0629 - val_loss: 0.0290 - val_mae: 0.1393\nEpoch 67/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0069 - mae: 0.0609 - val_loss: 0.0282 - val_mae: 0.1379\nEpoch 68/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0066 - mae: 0.0598 - val_loss: 0.0267 - val_mae: 0.1349\nEpoch 69/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0064 - mae: 0.0585 - val_loss: 0.0263 - val_mae: 0.1334\nEpoch 70/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0064 - mae: 0.0589 - val_loss: 0.0276 - val_mae: 0.1361\nEpoch 71/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795ms/step - loss: 0.0064 - mae: 0.0586Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.66-0.0290.weights.h5\nRemoving old checkpoint: denoising_autoencoder.65-0.0291.weights.h5\nRemoving old checkpoint: denoising_autoencoder.64-0.0299.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0064 - mae: 0.0591 - val_loss: 0.0272 - val_mae: 0.1353\nEpoch 72/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0068 - mae: 0.0610 - val_loss: 0.0244 - val_mae: 0.1287\nEpoch 73/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0071 - mae: 0.0623 - val_loss: 0.0250 - val_mae: 0.1298\nEpoch 74/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0065 - mae: 0.0590 - val_loss: 0.0252 - val_mae: 0.1299\nEpoch 75/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0064 - mae: 0.0585 - val_loss: 0.0255 - val_mae: 0.1302\nEpoch 76/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700ms/step - loss: 0.0065 - mae: 0.0594Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.67-0.0282.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0064 - mae: 0.0589 - val_loss: 0.0247 - val_mae: 0.1287\nEpoch 77/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0064 - mae: 0.0587 - val_loss: 0.0238 - val_mae: 0.1271\nEpoch 78/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0064 - mae: 0.0583 - val_loss: 0.0238 - val_mae: 0.1264\nEpoch 79/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0063 - mae: 0.0579 - val_loss: 0.0232 - val_mae: 0.1242\nEpoch 80/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0065 - mae: 0.0594 - val_loss: 0.0244 - val_mae: 0.1272\nEpoch 81/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792ms/step - loss: 0.0066 - mae: 0.0597Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.69-0.0263.weights.h5\nRemoving old checkpoint: denoising_autoencoder.68-0.0267.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0067 - mae: 0.0599 - val_loss: 0.0235 - val_mae: 0.1250\nEpoch 82/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0063 - mae: 0.0585 - val_loss: 0.0228 - val_mae: 0.1233\nEpoch 83/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0064 - mae: 0.0590 - val_loss: 0.0225 - val_mae: 0.1220\nEpoch 84/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0062 - mae: 0.0576 - val_loss: 0.0211 - val_mae: 0.1183\nEpoch 85/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0062 - mae: 0.0580 - val_loss: 0.0217 - val_mae: 0.1207\nEpoch 86/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786ms/step - loss: 0.0059 - mae: 0.0564Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.79-0.0232.weights.h5\nRemoving old checkpoint: denoising_autoencoder.77-0.0238.weights.h5\nRemoving old checkpoint: denoising_autoencoder.72-0.0244.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0059 - mae: 0.0564 - val_loss: 0.0216 - val_mae: 0.1205\nEpoch 87/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0063 - mae: 0.0582 - val_loss: 0.0206 - val_mae: 0.1181\nEpoch 88/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0068 - mae: 0.0611 - val_loss: 0.0201 - val_mae: 0.1169\nEpoch 89/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0063 - mae: 0.0583 - val_loss: 0.0200 - val_mae: 0.1155\nEpoch 90/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0062 - mae: 0.0580 - val_loss: 0.0202 - val_mae: 0.1155\nEpoch 91/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791ms/step - loss: 0.0060 - mae: 0.0567Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.84-0.0211.weights.h5\nRemoving old checkpoint: denoising_autoencoder.83-0.0225.weights.h5\nRemoving old checkpoint: denoising_autoencoder.82-0.0228.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0062 - mae: 0.0579 - val_loss: 0.0203 - val_mae: 0.1171\nEpoch 92/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0058 - mae: 0.0559 - val_loss: 0.0190 - val_mae: 0.1140\nEpoch 93/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0061 - mae: 0.0572 - val_loss: 0.0190 - val_mae: 0.1134\nEpoch 94/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - loss: 0.0059 - mae: 0.0561 - val_loss: 0.0194 - val_mae: 0.1142\nEpoch 95/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0059 - mae: 0.0562 - val_loss: 0.0185 - val_mae: 0.1110\nEpoch 96/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673ms/step - loss: 0.0058 - mae: 0.0557Managing checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.89-0.0200.weights.h5\nRemoving old checkpoint: denoising_autoencoder.88-0.0201.weights.h5\nRemoving old checkpoint: denoising_autoencoder.87-0.0206.weights.h5\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0059 - mae: 0.0561 - val_loss: 0.0178 - val_mae: 0.1091\nEpoch 97/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0061 - mae: 0.0580 - val_loss: 0.0186 - val_mae: 0.1116\nEpoch 98/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0060 - mae: 0.0570 - val_loss: 0.0168 - val_mae: 0.1059\nEpoch 99/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.0059 - mae: 0.0568 - val_loss: 0.0165 - val_mae: 0.1048\nEpoch 100/100\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0064 - mae: 0.0589 - val_loss: 0.0183 - val_mae: 0.1108\nFinal model saved to denoising_autoencoder_final in TF SavedModel format\nFinal model also saved to denoising_autoencoder_final.h5\n\nTesting model with a simple example...\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\nTest results saved to test_results.png\nManaging checkpoints. Keeping 3 most recent checkpoints...\nRemoving old checkpoint: denoising_autoencoder.95-0.0185.weights.h5\nRemoving old checkpoint: denoising_autoencoder.92-0.0190.weights.h5\n\nSetup complete!\nModel and related files saved to: /kaggle/working/models\nLogs saved to: /kaggle/working/logs\n\nNext steps:\n1. Download the model files\n2. Use the SavedModel format at 'denoising_autoencoder_final' for best compatibility\n3. Alternatively, use the H5 model at 'denoising_autoencoder_final.h5'\n4. When loading the model, use tf.keras.models.load_model('/path/to/denoising_autoencoder_final')\n   or model = tf.keras.models.load_model('/path/to/denoising_autoencoder_final.h5')\n5. For best portability, avoid using mixed precision when loading and using the model\n6. View training results in TensorBoard with: tensorboard --logdir=/kaggle/working/logs\n","output_type":"stream"}],"execution_count":1}]}